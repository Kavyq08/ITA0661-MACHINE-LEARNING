import numpy as np
from collections import defaultdict
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.metrics import confusion_matrix, accuracy_score

class NaiveBayes:
    def fit(self, X_train, y_train):
        self.classes = np.unique(y_train)
        self.class_prob = {}
        self.feature_prob = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))
        
        for c in self.classes:
            X_c = X_train[y_train == c]
            self.class_prob[c] = len(X_c) / len(X_train)
            for feature_idx in range(X_train.shape[1]):
                feature_values = X_c[:, feature_idx]
                feature_value_counts = defaultdict(int)
                for value in feature_values:
                    feature_value_counts[value] += 1
                total_count = len(feature_values)
                for value, count in feature_value_counts.items():
                    self.feature_prob[c][feature_idx][value] = count / total_count
    
    def predict(self, X_test):
        predictions = [self._predict(x) for x in X_test]
        return np.array(predictions)
    
    def _predict(self, x):
        class_probs = {}
        for c in self.classes:
            prob = np.log(self.class_prob[c])
            for feature_idx, value in enumerate(x):
                prob += np.log(self.feature_prob[c][feature_idx].get(value, 1e-6))
            class_probs[c] = prob
        return max(class_probs, key=class_probs.get)

data = load_iris()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

nb = NaiveBayes()
nb.fit(X_train, y_train)
y_pred = nb.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)

print("Confusion Matrix:")
print(cm)
print(f"Accuracy: {accuracy}")
